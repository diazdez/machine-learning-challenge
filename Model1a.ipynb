{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING CHALLENGE\n",
    "# Exoplanet Exploration: Model1a\n",
    "Note: This model is using Logistic Regression\n",
    "\n",
    "*Model1a will use a selected number of columns for this model (Selected Features will confirm the various accuracy results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in c:\\users\\diazd\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\diazd\\anaconda3\\lib\\site-packages (from sklearn) (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\diazd\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\diazd\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\diazd\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\diazd\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\diazd\\anaconda3\\lib\\site-packages (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV & Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowid</th>\n",
       "      <th>kepid</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9.564000e+03</td>\n",
       "      <td>8054.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>9110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9081.000000</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>9096.000000</td>\n",
       "      <td>9096.000000</td>\n",
       "      <td>9201.000000</td>\n",
       "      <td>9096.000000</td>\n",
       "      <td>9096.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9564.000000</td>\n",
       "      <td>9563.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4782.500000</td>\n",
       "      <td>7.690628e+06</td>\n",
       "      <td>0.480829</td>\n",
       "      <td>0.188206</td>\n",
       "      <td>0.231598</td>\n",
       "      <td>0.194898</td>\n",
       "      <td>0.120033</td>\n",
       "      <td>75.671358</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>-0.002148</td>\n",
       "      <td>...</td>\n",
       "      <td>-162.265059</td>\n",
       "      <td>4.310157</td>\n",
       "      <td>0.120738</td>\n",
       "      <td>-0.143161</td>\n",
       "      <td>1.728712</td>\n",
       "      <td>0.362292</td>\n",
       "      <td>-0.394806</td>\n",
       "      <td>292.060163</td>\n",
       "      <td>43.810433</td>\n",
       "      <td>14.264606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2761.033321</td>\n",
       "      <td>2.653459e+06</td>\n",
       "      <td>0.476928</td>\n",
       "      <td>0.390897</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.396143</td>\n",
       "      <td>0.325018</td>\n",
       "      <td>1334.744046</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>0.008236</td>\n",
       "      <td>...</td>\n",
       "      <td>72.746348</td>\n",
       "      <td>0.432606</td>\n",
       "      <td>0.132837</td>\n",
       "      <td>0.085477</td>\n",
       "      <td>6.127185</td>\n",
       "      <td>0.930870</td>\n",
       "      <td>2.168213</td>\n",
       "      <td>4.766657</td>\n",
       "      <td>3.601243</td>\n",
       "      <td>1.385448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.574500e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.172500</td>\n",
       "      <td>...</td>\n",
       "      <td>-1762.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.207000</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-116.137000</td>\n",
       "      <td>279.852720</td>\n",
       "      <td>36.577381</td>\n",
       "      <td>6.966000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2391.750000</td>\n",
       "      <td>5.556034e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.733684</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>...</td>\n",
       "      <td>-198.000000</td>\n",
       "      <td>4.218000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>-0.196000</td>\n",
       "      <td>0.829000</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>288.660770</td>\n",
       "      <td>40.777173</td>\n",
       "      <td>13.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4782.500000</td>\n",
       "      <td>7.906892e+06</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.752831</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>-160.000000</td>\n",
       "      <td>4.438000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.128000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>-0.111000</td>\n",
       "      <td>292.261125</td>\n",
       "      <td>43.677504</td>\n",
       "      <td>14.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7173.250000</td>\n",
       "      <td>9.873066e+06</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.715178</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>-114.000000</td>\n",
       "      <td>4.543000</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>-0.088000</td>\n",
       "      <td>1.345000</td>\n",
       "      <td>0.364000</td>\n",
       "      <td>-0.069000</td>\n",
       "      <td>295.859160</td>\n",
       "      <td>46.714611</td>\n",
       "      <td>15.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9564.000000</td>\n",
       "      <td>1.293514e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>129995.778400</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.364000</td>\n",
       "      <td>1.472000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>229.908000</td>\n",
       "      <td>33.091000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>301.720760</td>\n",
       "      <td>52.336010</td>\n",
       "      <td>20.003000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rowid         kepid    koi_score  koi_fpflag_nt  koi_fpflag_ss  \\\n",
       "count  9564.000000  9.564000e+03  8054.000000    9564.000000    9564.000000   \n",
       "mean   4782.500000  7.690628e+06     0.480829       0.188206       0.231598   \n",
       "std    2761.033321  2.653459e+06     0.476928       0.390897       0.421875   \n",
       "min       1.000000  7.574500e+05     0.000000       0.000000       0.000000   \n",
       "25%    2391.750000  5.556034e+06     0.000000       0.000000       0.000000   \n",
       "50%    4782.500000  7.906892e+06     0.334000       0.000000       0.000000   \n",
       "75%    7173.250000  9.873066e+06     0.998000       0.000000       0.000000   \n",
       "max    9564.000000  1.293514e+07     1.000000       1.000000       1.000000   \n",
       "\n",
       "       koi_fpflag_co  koi_fpflag_ec     koi_period  koi_period_err1  \\\n",
       "count    9564.000000    9564.000000    9564.000000      9110.000000   \n",
       "mean        0.194898       0.120033      75.671358         0.002148   \n",
       "std         0.396143       0.325018    1334.744046         0.008236   \n",
       "min         0.000000       0.000000       0.241843         0.000000   \n",
       "25%         0.000000       0.000000       2.733684         0.000005   \n",
       "50%         0.000000       0.000000       9.752831         0.000035   \n",
       "75%         0.000000       0.000000      40.715178         0.000276   \n",
       "max         1.000000       1.000000  129995.778400         0.172500   \n",
       "\n",
       "       koi_period_err2  ...  koi_steff_err2    koi_slogg  koi_slogg_err1  \\\n",
       "count      9110.000000  ...     9081.000000  9201.000000     9096.000000   \n",
       "mean         -0.002148  ...     -162.265059     4.310157        0.120738   \n",
       "std           0.008236  ...       72.746348     0.432606        0.132837   \n",
       "min          -0.172500  ...    -1762.000000     0.047000        0.000000   \n",
       "25%          -0.000276  ...     -198.000000     4.218000        0.042000   \n",
       "50%          -0.000035  ...     -160.000000     4.438000        0.070000   \n",
       "75%          -0.000005  ...     -114.000000     4.543000        0.149000   \n",
       "max           0.000000  ...        0.000000     5.364000        1.472000   \n",
       "\n",
       "       koi_slogg_err2     koi_srad  koi_srad_err1  koi_srad_err2           ra  \\\n",
       "count     9096.000000  9201.000000    9096.000000    9096.000000  9564.000000   \n",
       "mean        -0.143161     1.728712       0.362292      -0.394806   292.060163   \n",
       "std          0.085477     6.127185       0.930870       2.168213     4.766657   \n",
       "min         -1.207000     0.109000       0.000000    -116.137000   279.852720   \n",
       "25%         -0.196000     0.829000       0.129000      -0.250000   288.660770   \n",
       "50%         -0.128000     1.000000       0.251000      -0.111000   292.261125   \n",
       "75%         -0.088000     1.345000       0.364000      -0.069000   295.859160   \n",
       "max          0.000000   229.908000      33.091000       0.000000   301.720760   \n",
       "\n",
       "               dec   koi_kepmag  \n",
       "count  9564.000000  9563.000000  \n",
       "mean     43.810433    14.264606  \n",
       "std       3.601243     1.385448  \n",
       "min      36.577381     6.966000  \n",
       "25%      40.777173    13.440000  \n",
       "50%      43.677504    14.520000  \n",
       "75%      46.714611    15.322000  \n",
       "max      52.336010    20.003000  \n",
       "\n",
       "[8 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# csv file obtained from Kaggle\n",
    "\n",
    "df = pd.read_csv ('cumulative.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9564, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rowid', 'kepid', 'kepoi_name', 'kepler_name', 'koi_disposition',\n",
       "       'koi_pdisposition', 'koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss',\n",
       "       'koi_fpflag_co', 'koi_fpflag_ec', 'koi_period', 'koi_period_err1',\n",
       "       'koi_period_err2', 'koi_time0bk', 'koi_time0bk_err1',\n",
       "       'koi_time0bk_err2', 'koi_impact', 'koi_impact_err1', 'koi_impact_err2',\n",
       "       'koi_duration', 'koi_duration_err1', 'koi_duration_err2', 'koi_depth',\n",
       "       'koi_depth_err1', 'koi_depth_err2', 'koi_prad', 'koi_prad_err1',\n",
       "       'koi_prad_err2', 'koi_teq', 'koi_teq_err1', 'koi_teq_err2', 'koi_insol',\n",
       "       'koi_insol_err1', 'koi_insol_err2', 'koi_model_snr', 'koi_tce_plnt_num',\n",
       "       'koi_tce_delivname', 'koi_steff', 'koi_steff_err1', 'koi_steff_err2',\n",
       "       'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2', 'koi_srad',\n",
       "       'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec', 'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_pdisposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.775000e-05</td>\n",
       "      <td>-2.775000e-05</td>\n",
       "      <td>170.538750</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.494000e-05</td>\n",
       "      <td>-1.494000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.761000e-06</td>\n",
       "      <td>-3.761000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.589871</td>\n",
       "      <td>1.846000e-04</td>\n",
       "      <td>-1.846000e-04</td>\n",
       "      <td>132.016100</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>...</td>\n",
       "      <td>-152.0</td>\n",
       "      <td>4.296</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>298.74921</td>\n",
       "      <td>46.973351</td>\n",
       "      <td>14.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527699</td>\n",
       "      <td>1.160000e-07</td>\n",
       "      <td>-1.160000e-07</td>\n",
       "      <td>131.705093</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>...</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>297.18875</td>\n",
       "      <td>47.093819</td>\n",
       "      <td>14.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.739849</td>\n",
       "      <td>1.780000e-05</td>\n",
       "      <td>-1.780000e-05</td>\n",
       "      <td>133.001270</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>...</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>4.444</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>286.50937</td>\n",
       "      <td>47.163219</td>\n",
       "      <td>14.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681402</td>\n",
       "      <td>2.434000e-06</td>\n",
       "      <td>-2.434000e-06</td>\n",
       "      <td>132.181750</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>...</td>\n",
       "      <td>-236.0</td>\n",
       "      <td>4.447</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>294.16489</td>\n",
       "      <td>47.176281</td>\n",
       "      <td>15.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.856035</td>\n",
       "      <td>6.356000e-05</td>\n",
       "      <td>-6.356000e-05</td>\n",
       "      <td>135.993300</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>...</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>4.385</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>297.00977</td>\n",
       "      <td>47.121021</td>\n",
       "      <td>14.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8744 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     koi_pdisposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "0           CANDIDATE              0              0              0   \n",
       "1           CANDIDATE              0              0              0   \n",
       "2      FALSE POSITIVE              0              1              0   \n",
       "3      FALSE POSITIVE              0              1              0   \n",
       "4           CANDIDATE              0              0              0   \n",
       "...               ...            ...            ...            ...   \n",
       "9559   FALSE POSITIVE              0              0              0   \n",
       "9560   FALSE POSITIVE              0              1              1   \n",
       "9561        CANDIDATE              0              0              0   \n",
       "9562   FALSE POSITIVE              0              0              1   \n",
       "9563   FALSE POSITIVE              0              0              1   \n",
       "\n",
       "      koi_fpflag_ec  koi_period  koi_period_err1  koi_period_err2  \\\n",
       "0                 0    9.488036     2.775000e-05    -2.775000e-05   \n",
       "1                 0   54.418383     2.479000e-04    -2.479000e-04   \n",
       "2                 0   19.899140     1.494000e-05    -1.494000e-05   \n",
       "3                 0    1.736952     2.630000e-07    -2.630000e-07   \n",
       "4                 0    2.525592     3.761000e-06    -3.761000e-06   \n",
       "...             ...         ...              ...              ...   \n",
       "9559              1    8.589871     1.846000e-04    -1.846000e-04   \n",
       "9560              0    0.527699     1.160000e-07    -1.160000e-07   \n",
       "9561              0    1.739849     1.780000e-05    -1.780000e-05   \n",
       "9562              0    0.681402     2.434000e-06    -2.434000e-06   \n",
       "9563              1    4.856035     6.356000e-05    -6.356000e-05   \n",
       "\n",
       "      koi_time0bk  koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  \\\n",
       "0      170.538750          0.002160  ...           -81.0      4.467   \n",
       "1      162.513840          0.003520  ...           -81.0      4.467   \n",
       "2      175.850252          0.000581  ...          -176.0      4.544   \n",
       "3      170.307565          0.000115  ...          -174.0      4.564   \n",
       "4      171.595550          0.001130  ...          -211.0      4.438   \n",
       "...           ...               ...  ...             ...        ...   \n",
       "9559   132.016100          0.015700  ...          -152.0      4.296   \n",
       "9560   131.705093          0.000170  ...          -166.0      4.529   \n",
       "9561   133.001270          0.007690  ...          -220.0      4.444   \n",
       "9562   132.181750          0.002850  ...          -236.0      4.447   \n",
       "9563   135.993300          0.010800  ...          -225.0      4.385   \n",
       "\n",
       "      koi_slogg_err1  koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2  \\\n",
       "0              0.064          -0.096     0.927          0.105         -0.061   \n",
       "1              0.064          -0.096     0.927          0.105         -0.061   \n",
       "2              0.044          -0.176     0.868          0.233         -0.078   \n",
       "3              0.053          -0.168     0.791          0.201         -0.067   \n",
       "4              0.070          -0.210     1.046          0.334         -0.133   \n",
       "...              ...             ...       ...            ...            ...   \n",
       "9559           0.231          -0.189     1.088          0.313         -0.228   \n",
       "9560           0.035          -0.196     0.903          0.237         -0.079   \n",
       "9561           0.056          -0.224     1.031          0.341         -0.114   \n",
       "9562           0.056          -0.224     1.041          0.341         -0.114   \n",
       "9563           0.054          -0.216     1.193          0.410         -0.137   \n",
       "\n",
       "             ra        dec  koi_kepmag  \n",
       "0     291.93423  48.141651      15.347  \n",
       "1     291.93423  48.141651      15.347  \n",
       "2     297.00482  48.134129      15.436  \n",
       "3     285.53461  48.285210      15.597  \n",
       "4     288.75488  48.226200      15.509  \n",
       "...         ...        ...         ...  \n",
       "9559  298.74921  46.973351      14.478  \n",
       "9560  297.18875  47.093819      14.082  \n",
       "9561  286.50937  47.163219      14.757  \n",
       "9562  294.16489  47.176281      15.385  \n",
       "9563  297.00977  47.121021      14.826  \n",
       "\n",
       "[8744 rows x 41 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#  Remove features \n",
    "df = df.drop(columns=['rowid', 'kepid', 'kepoi_name', 'kepler_name', 'koi_disposition', 'koi_score', 'koi_tce_delivname'])\n",
    "\n",
    "\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_pdisposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
       "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
       "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
       "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
       "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
       "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
       "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
       "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
       "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
       "       'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remaining columns (9 were removed)\n",
    "df.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Select your features (columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "\n",
    "\n",
    "\n",
    "selected1_features = df[['koi_fpflag_nt',\n",
    "                        'koi_fpflag_ss',\n",
    "                        'koi_fpflag_co',\n",
    "                        'koi_srad_err2',\n",
    "                        'ra','dec',\n",
    "                        'koi_kepmag']]\n",
    "\n",
    "selected2_features = df[['koi_teq', \n",
    "                        'koi_insol', \n",
    "                        'koi_insol_err1', \n",
    "                        'koi_insol_err2',\n",
    "                        'koi_srad_err2',\n",
    "                        'ra','dec',\n",
    "                        'koi_kepmag']]\n",
    "\n",
    "selected3_features = df[['koi_fpflag_nt','koi_fpflag_ss', \n",
    "                       'koi_time0bk', \n",
    "                       'koi_time0bk_err1', \n",
    "                       'koi_time0bk_err2', \n",
    "                        'koi_insol_err1', \n",
    "                        'koi_insol_err2',\n",
    "                        'koi_srad_err2',\n",
    "                        'ra','dec',\n",
    "                        'koi_kepmag']]\n",
    "\n",
    "\n",
    "selected4_features = df[['koi_fpflag_nt', \n",
    "                         'koi_fpflag_ss', \n",
    "                         'koi_fpflag_co',\n",
    "                         'koi_fpflag_ec']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Create a Train Test Split \n",
    "Use koi_disposition for the y values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# identify X and y variables\n",
    "\n",
    "y = df[\"koi_pdisposition\"]  \n",
    "X = selected3_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split the data to train and test values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " # random sample of label and features\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>koi_time0bk_err2</th>\n",
       "      <th>koi_insol_err1</th>\n",
       "      <th>koi_insol_err2</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167.579000</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>-0.113000</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>282.37042</td>\n",
       "      <td>48.259289</td>\n",
       "      <td>16.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5360</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132.218114</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>198.02</td>\n",
       "      <td>-90.41</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>290.93845</td>\n",
       "      <td>37.701172</td>\n",
       "      <td>16.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>134.508670</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>55.67</td>\n",
       "      <td>-64.24</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>294.91586</td>\n",
       "      <td>45.783871</td>\n",
       "      <td>15.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7896</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148.509200</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>-0.013300</td>\n",
       "      <td>20.61</td>\n",
       "      <td>-7.04</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>293.90091</td>\n",
       "      <td>38.308689</td>\n",
       "      <td>15.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131.714470</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>-0.001350</td>\n",
       "      <td>2678.53</td>\n",
       "      <td>-931.70</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>298.65317</td>\n",
       "      <td>47.713711</td>\n",
       "      <td>15.546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_time0bk  koi_time0bk_err1  \\\n",
       "3380              0              0   167.579000          0.113000   \n",
       "5360              0              1   132.218114          0.000761   \n",
       "834               0              1   134.508670          0.000314   \n",
       "7896              0              0   148.509200          0.013300   \n",
       "2826              0              0   131.714470          0.001350   \n",
       "\n",
       "      koi_time0bk_err2  koi_insol_err1  koi_insol_err2  koi_srad_err2  \\\n",
       "3380         -0.113000            0.74           -0.64         -0.056   \n",
       "5360         -0.000761          198.02          -90.41         -0.046   \n",
       "834          -0.000314           55.67          -64.24         -0.054   \n",
       "7896         -0.013300           20.61           -7.04         -0.067   \n",
       "2826         -0.001350         2678.53         -931.70         -0.067   \n",
       "\n",
       "             ra        dec  koi_kepmag  \n",
       "3380  282.37042  48.259289      16.324  \n",
       "5360  290.93845  37.701172      16.654  \n",
       "834   294.91586  45.783871      15.702  \n",
       "7896  293.90091  38.308689      15.380  \n",
       "2826  298.65317  47.713711      15.546  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing \n",
    "Use MinMaxScaler to scale the numerical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referenced: https://www.geeksforgeeks.org/data-preprocessing-machine-learning-python/\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale your data\n",
    "\n",
    "X_scale = MinMaxScaler().fit(X_train) \n",
    "\n",
    "X_train_scaled = X_scale.transform(X_train)\n",
    "X_test_scaled = X_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.06847749, ..., 0.58909669, 0.80928728,\n",
       "        0.55789735],\n",
       "       [0.        , 0.        , 0.00884773, ..., 0.52956598, 0.32528598,\n",
       "        0.54062319],\n",
       "       [1.        , 0.        , 0.00792182, ..., 0.52391115, 0.38322744,\n",
       "        0.69873543],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.27949502, ..., 0.76285163, 0.8381738 ,\n",
       "        0.57062567],\n",
       "       [0.        , 0.        , 0.00845286, ..., 0.61831056, 0.32029931,\n",
       "        0.52822547],\n",
       "       [0.        , 1.        , 0.00778316, ..., 0.87532765, 0.64948715,\n",
       "        0.51243904]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Sample testing\n",
    "X_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: koi_disposition for the y values; so need to apply label-encode function (??) \n",
    "# ENCODER not necessary when using LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FALSE POSITIVE', 'CANDIDATE', 'FALSE POSITIVE', ..., 'CANDIDATE',\n",
       "       'CANDIDATE', 'FALSE POSITIVE'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# fit the data and make predictions\n",
    "\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8854833790789874\n",
      "Testing Data Score: 0.8815187557182068\n"
     ]
    }
   ],
   "source": [
    "# Using some/random columns (not all) will result in a different (low score)\n",
    "\n",
    "\n",
    "print(f\"Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "When hyper-parameter tuning, some models have parameters that depend on each other, and certain combinations will not create a valid model. Be sure to read through any warning messages and check the documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the GridSearchCV model\n",
    "\n",
    "# param_grid = {'C': [10, 50, 100],\n",
    "#              'max_iter':[200, 500, 1000]}\n",
    "\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'penalty': [\"l1\", \"l2\"]}\n",
    "\n",
    "grid = GridSearchCV(model,param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] ....................... C=1, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.889, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, penalty=l2, score=0.890, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.878, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.881, total=   0.1s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] ..................... C=1, penalty=l2, score=0.889, total=   0.1s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ....................... C=5, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ....................... C=5, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ....................... C=5, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ....................... C=5, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=5, penalty=l1 .................................................\n",
      "[CV] ....................... C=5, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.889, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, penalty=l2, score=0.890, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.878, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, penalty=l2, score=0.880, total=   0.1s\n",
      "[CV] C=5, penalty=l2 .................................................\n",
      "[CV] ..................... C=5, penalty=l2, score=0.889, total=   0.1s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ...................... C=10, penalty=l1, score=nan, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, penalty=l2, score=0.889, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.890, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.878, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.880, total=   0.1s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] .................... C=10, penalty=l2, score=0.889, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diazd\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 5, 10], 'penalty': ['l1', 'l2']}, verbose=3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the model with GridSearch\n",
    "\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l2'}\n",
      "0.8853307380327807\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exoplanet_model1a.sav']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "filename = 'exoplanet_model1a.sav'\n",
    "joblib.dump(model, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8815187557182068\n"
     ]
    }
   ],
   "source": [
    "# load the model from disk\n",
    "\n",
    "loaded_model1a = joblib.load(filename)\n",
    "result = loaded_model1a.score(X_test_scaled, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
